<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="description"
    content="HERO">
    <meta name="keywords" content="Human Motion Generation, Human Reaction Generation, Interactive AI">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>HERO: Human Reaction Generation from Videos</title>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">

    <style>
        .overline {
            text-decoration: overline;
        }
        h2 {
            text-align: center;
        }
        p {
            text-align: justify;
        }
        .render_wrapper_small {
			      position: relative;
            height: 200px;
         }
         .render_wrapper {
            position: relative;
            max-height: 400px;
            height: auto;
            width: auto;
        }
        .render_wrapper_relative {
            position: relative;
            max-height: 300px;
            max-width: 300px;
            height: auto;
            width: auto;
        }
        .render_wrapper_relative>img {
          width: 300px;
          height: 300px;
        }
        .render_div {
            position: absolute;
            top: 0;
            left: 0;
        }
        #interpolation-image-wrapper-car{
            text-align: center;
        }
        #interpolation-image-wrapper-chair{
            text-align: center;
        }
        .nested-columns {
            margin-bottom: 0 !important;
        }
    </style>

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
</head>

<body>

    <nav class="navbar" role="navigation" aria-label="main navigation">
        <div class="navbar-brand">
          <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
          </a>
        </div>
        <div class="navbar-menu">
          <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
            <a class="navbar-item" href="">
            <span class="icon">
                <i class="fas fa-home"></i>
            </span>
            </a>
      
            <div class="navbar-item has-dropdown is-hoverable">
              <a class="navbar-link">
                More Research
              </a>
              <div class="navbar-dropdown">
                <a class="navbar-item" href="https://yyvhang.github.io/EgoChoir/"> 
                  EgoChoir
                </a>
                <a class="navbar-item" href="https://yyvhang.github.io/LEMON/"> 
                  LEMON
                </a>
                <a class="navbar-item" href="https://yyvhang.github.io/publications/IAG/index.html">
                  IAG-Net
                </a>
              </div>
            </div>
          </div>
      
        </div>
    </nav>

    <section class="hero">
        <div class="hero-body">
          <div class="container is-max-desktop">
            <div class="columns is-centered">
              <div class="column has-text-centered">
                <h1 class="title is-1 publication-title">HERO: Human Reaction Generation from Videos</h1>
                <!-- <h2 class="title is-3" style="color: red;">CVPR2024</h2> -->
                <div class="is-size-5 publication-authors">
                  <span class="author-block">
                    <a href="">Chengjun Yu</a><sup>1</sup>,</span>
                  <span class="author-block">
                    <a href="https://tiaotiao11-22.github.io/wzhai">Wei Zhai</a><sup>1</sup>,</span>
                  <span class="author-block">
                    <a href="https://yyvhang.github.io">Yuhang Yang</a><sup>1</sup>,
                  </span>
                  <span class="author-block">
                    <a href="https://scholar.google.com.hk/citations?hl=zh-CN&user=K7rTHNcAAAAJ">Yang Cao</a><sup>1,2</sup>,
                  </span>
                  <span class="author-block">
                    <a href="https://scholar.google.com.hk/citations?hl=zh-CN&user=gDnBC1gAAAAJ">Zheng-Jun Zha</a><sup>1</sup>,
                  </span>
                </div>
      
                <div class="is-size-5 publication-authors">
                  <span class="author-block"><sup>1</sup>University of Science and Technology of China</span>
                  <span class="author-block"><sup>2</sup>Institute of Artificial Intelligence, Hefei Comprehensive National Science Center</span>
                </div>
      
                <div class="column has-text-centered">
                  <div class="publication-links">
                    <!-- PDF Link. -->
                    <span class="link-block">
                      <a href="https://arxiv.org/pdf/2503.08270"
                         class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                            <i class="ai ai-arxiv"></i>
                        </span>
                        <span>arXiv</span>
                      </a>
                    </span>
                    <!-- Video Link. -->
                    <!-- <span class="link-block">
                      <a href=""
                         class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                            <i class="fab fa-youtube"></i>
                        </span>
                        <span>Video</span>
                      </a>
                    </span> -->
                    <!-- Code Link. -->
                    <span class="link-block">
                      <a href=""
                         class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                            <i class="fab fa-github"></i>
                        </span>
                        <span>Code</span>
                        </a>
                    </span>
                    <!-- Dataset Link. -->
                    <span class="link-block">
                      <a href=""
                         class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                            <i class="far fa-images"></i>
                        </span>
                        <span>Dataset</span>
                        </a>
                  </div>
      
                </div>
              </div>
            </div>
          </div>
        </div>
    </section>

    <section class="hero teaser">
        <div class="container is-max-desktop">
            <div class="hero-body">
                <img src="./static/images/teaser.png" height="200%" />
                  <p>
                    <b>Overview of our work.</b> We propose to generate 3D human reactions from RGB videos. To tackle this task, a simple yet powerful 
                    framework, HERO, is presented. Furthermore, to facilitate research in this area, we introduce the ViMo dataset, which features 
                    a wide range of interaction categories covering three broad ones: <span style="color: rgb(0, 0, 255);">human-human interactions</span>, 
                    <span style="color: rgb(0, 160, 0);">animal-human interactions</span>, and <span style="color: rgb(255, 0, 0);">scene-human interactions</span>. 
                    For the human reactions visualized in the figure, the darker colors indicate the later in time.
                  </p>
            </div>
        </div>
    </section>
<!--
    <section class="hero is-light is-small">
        <div class="hero-body">
            <div class="container">
                <div id="results-carousel" class="carousel results-carousel">
                    <div class="outer-div">
                        <div class="item item-steve render_wrapper_relative">
                          <img src="./static/images/R_skateboard1.png" srcset="./static/images/R_skateboard1.png 1000w, ./static/images/R_skateboard1.png 2000w" sizes="(width: 300px) 300px, 1000px" alt="">
                        </div>
                    </div>
                  <div class="outer-div">
                    <div class="item item-steve render_wrapper_relative">
                      <img src="./static/images/R_skateboard2.png" srcset="./static/images/R_skateboard2.png 1000w, ./static/images/R_skateboard2.png 2000w" sizes="(width: 300px) 300px, 1000px" alt="">
                    </div>
                  </div>
                  <div class="outer-div">
                    <div class="item item-steve render_wrapper_relative">
                      <img src="./static/images/R_bottle1.png" srcset="./static/images/R_bottle1.png 1000w, ./static/images/R_bottle1.png 2000w" sizes="(width: 300px) 300px, 1000px" alt="">
                    </div>
                  </div>
                  <div class="outer-div">
                    <div class="item item-steve render_wrapper_relative">
                      <img src="./static/images/R_bottle2.png" srcset="./static/images/R_bottle2.png 1000w, ./static/images/R_bottle2.png 2000w" sizes="(width: 300px) 300px, 1000px" alt="">
                    </div>
                  </div>
                  <div class="outer-div">
                    <div class="item item-steve render_wrapper_relative">
                      <img src="./static/images/R_Tennis1.png" srcset="./static/images/R_Tennis1.png 1000w, ./static/images/R_Tennis1.png 2000w" sizes="(width: 300px) 300px, 1000px" alt="">
                    </div>
                  </div>
                  <div class="outer-div">
                    <div class="item item-steve render_wrapper_relative">
                      <img src="./static/images/R_Tennis2.png" srcset="./static/images/R_Tennis2.png 1000w, ./static/images/R_Tennis2.png 2000w" sizes="(width: 300px) 300px, 1000px" alt="">
                    </div>
                  </div>
                  <div class="outer-div">
                    <div class="item item-steve render_wrapper_relative">
                      <img src="./static/images/R_motor1.png" srcset="./static/images/R_motor1.png 1000w, ./static/images/R_motor1.png 2000w" sizes="(width: 300px) 300px, 1000px" alt="">
                    </div>
                  </div>
                  <div class="outer-div">
                    <div class="item item-steve render_wrapper_relative">
                      <img src="./static/images/R_motor2.png" srcset="./static/images/R_motor2.png 1000w, ./static/images/R_motor2.png 2000w" sizes="(width: 300px) 300px, 1000px" alt="">
                    </div>
                  </div>
                  <div class="outer-div">
                    <div class="item item-steve render_wrapper_relative">
                      <img src="./static/images/R_bowl1.png" srcset="./static/images/R_bowl1.png 1000w, ./static/images/R_bowl1.png 2000w" sizes="(width: 300px) 300px, 1000px" alt="">
                    </div>
                  </div>
                  <div class="outer-div">
                    <div class="item item-steve render_wrapper_relative">
                      <img src="./static/images/R_bowl2.png" srcset="./static/images/R_bowl2.png 1000w, ./static/images/R_bowl2.png 2000w" sizes="(width: 300px) 300px, 1000px" alt="">
                    </div>
                  </div>
                  <div class="outer-div">
                    <div class="item item-steve render_wrapper_relative">
                      <img src="./static/images/R_mug1_1.png" srcset="./static/images/R_mug1_1.png 1000w, ./static/images/R_mug1_1.png 2000w" sizes="(width: 300px) 300px, 1000px" alt="">
                    </div>
                  </div>
                  <div class="outer-div">
                    <div class="item item-steve render_wrapper_relative">
                      <img src="./static/images/R_mug1_2.png" srcset="./static/images/R_mug1_2.png 1000w, ./static/images/R_mug1_2.png 2000w" sizes="(width: 300px) 300px, 1000px" alt="">
                    </div>
                  </div>
                  <div class="outer-div">
                    <div class="item item-steve render_wrapper_relative">
                      <img src="./static/images/R_mug2_1.png" srcset="./static/images/R_mug2_1.png 1000w, ./static/images/R_mug2_1.png 2000w" sizes="(width: 300px) 300px, 1000px" alt="">
                    </div>
                  </div>
                  <div class="outer-div">
                    <div class="item item-steve render_wrapper_relative">
                      <img src="./static/images/R_mug2_2.png" srcset="./static/images/R_mug2_2.png 1000w, ./static/images/R_mug2_2.png 2000w" sizes="(width: 300px) 300px, 1000px" alt="">
                    </div>
                  </div>
                  <div class="outer-div">
                    <div class="item item-steve render_wrapper_relative">
                      <img src="./static/images/R_bed1.png" srcset="./static/images/R_bed1.png 1000w, ./static/images/R_bed1.png 2000w" sizes="(width: 300px) 300px, 1000px" alt="">
                    </div>
                  </div>
                  <div class="outer-div">
                    <div class="item item-steve render_wrapper_relative">
                      <img src="./static/images/R_bed2.png" srcset="./static/images/R_bed2.png 1000w, ./static/images/R_bed2.png 2000w" sizes="(width: 300px) 300px, 1000px" alt="">
                    </div>
                  </div>
                  <div class="outer-div">
                    <div class="item item-steve render_wrapper_relative">
                      <img src="./static/images/R_scissors1.png" srcset="./static/images/R_scissors1.png 1000w, ./static/images/R_scissors1.png 2000w" sizes="(width: 300px) 300px, 1000px" alt="">
                    </div>
                  </div>
                  <div class="outer-div">
                    <div class="item item-steve render_wrapper_relative">
                      <img src="./static/images/R_scissors2.png" srcset="./static/images/R_scissors2.png 1000w, ./static/images/R_scissors2.png 2000w" sizes="(width: 300px) 300px, 1000px" alt="">
                    </div>
                  </div>
                </div>
                <div style="text-align: center;">Interaction elements inferred by LEMON. Including human <span style="color: rgb(224.4,209.1,91.8);">contact</span>, object <span style="color: rgb(255, 0, 0);">affordance</span>, and two views of human-object spatial relation, the <span style="color: rgb(191.0,188.0,176.0);">translucent sphere</span> is the object proxy.</div>
            </div>
        </div>
    </section>
<<<<<<< HEAD
-->

    <section class="hero is-light is-small">
        <div class="hero-body">
            <div class="container">
                <div id="results-carousel" class="carousel results-carousel">
                    <div class="item item-chair">
                        <video poster="" id="chair" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/lion_approaching.mp4"
                                    type="video/mp4">
                        </video>
                        <img src="./static/videos/lion_gen_res.gif" height="20%" />
                    </div>
                    <div class="item item-Earphone">
                      <video poster="" id="Earphone" autoplay controls muted loop playsinline height="100%">
                          <source src="./static/videos/dribbling.mp4"
                                  type="video/mp4">
                      </video>
                      <img src="./static/videos/dribbling_gen_res.gif" height="20%" />
                    </div>
                    <div class="item item-Bag">
                      <video poster="" id="Bag" autoplay controls muted loop playsinline height="100%">
                          <source src="./static/videos/explosion.mp4"
                                  type="video/mp4">
                      </video>
                      <img src="./static/videos/explosion_gen_res.gif" height="20%" />
                    </div>
                    <div class="item item-Knife">
                      <video poster="" id="Knife" autoplay controls muted loop playsinline height="100%">
                          <source src="./static/videos/shooting.mp4"
                                  type="video/mp4">
                      </video>
                      <img src="./static/videos/shooting_gen_res.gif" height="20%" />
                    </div>
                    <div class="item item-Surfboard-carry">
                        <video poster="" id="Surfboard-carry" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/automobile_rushing_towards.mp4"
                                    type="video/mp4">
                        </video>
                        <img src="./static/videos/automobile_gen_res.gif" height="20%" />
                    </div>
                </div>
                <div style="text-align: center;">Generation results of different categories of interactions.</div>
            </div>
        </div>
    </section>

    <section class="hero is-light is-small">
      <div class="hero-body">
          <div class="container">
              <div id="results-carousel" class="carousel results-carousel">
                  <div class="item item-chair">
                      <video poster="" id="chair" autoplay controls muted loop playsinline height="100%">
                          <source src="./static/videos/walk_towards_happily.mp4"
                                  type="video/mp4">
                      </video>
                      <img src="./static/videos/w_h_gen_res.gif" height="20%" />
                  </div>
                  <div class="item item-Earphone">
                    <video poster="" id="Earphone" autoplay controls muted loop playsinline height="100%">
                        <source src="./static/videos/walk_towards_angrily.mp4"
                                type="video/mp4">
                    </video>
                    <img src="./static/videos/w_a_gen_res.gif" height="20%" />
                  </div>
                  <div class="item item-Bag">
                    <video poster="" id="Bag" autoplay controls muted loop playsinline height="100%">
                        <source src="./static/videos/walk_towards_expressionlessly.mp4"
                                type="video/mp4">
                    </video>
                    <img src="./static/videos/w_e_gen_res.gif" height="20%" />
                  </div>
              </div>
              <div style="text-align: center;">Generation results of "<i>walking towards</i>" with different emotions.</div>
          </div>
      </div>
  </section>

    <section class="section">
        <div class="container is-max-desktop">
          <!-- Abstract. -->
          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
              <h2 class="title is-3">Abstract</h2>
              <div class="content has-text-justified">
                <p>
                  Human reaction generation represents a significant research domain for interactive AI, as humans constantly interact with their 
                  surroundings. Previous works focus mainly on synthesizing the reactive motion given a human motion sequence. This paradigm limits 
                  interaction categories to human-human interactions and ignores emotions that may influence reaction generation. In this work, we 
                  propose to generate 3D human reactions from RGB videos, which involves a wider range of interaction categories and naturally provides 
                  information about expressions that may reflect the subject's emotions. To cope with this task, we present <b>HERO</b>, a simple yet 
                  powerful framework for <b>H</b>uman r<b>E</b>action gene<b>R</b>ation from vide<b>O</b>s. HERO considers both global and frame-level 
                  local representations of the video to extract the interaction intention, and then uses the extracted interaction intention to guide 
                  the synthesis of the reaction. Besides, local visual representations are continuously injected into the model to maximize the 
                  exploitation of the dynamic properties inherent in videos. Furthermore, the <b>ViMo</b> dataset containing paired 
                  <b>Vi</b>deo-<b>Mo</b>tion data is collected to support the task. In addition to human-human interactions, these video-motion pairs 
                  also cover animal-human interactions and scene-human interactions. Extensive experiments demonstrate the superiority of our methodology.
                </p>
              </div>
            </div>
          </div>
          <!--/ Abstract. -->
      
          <!-- Paper video. -->
          <!-- <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
              <h2 class="title is-3">Video</h2>
              <div class="publication-video">
                <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                        frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
              </div>
            </div>
          </div> -->
          <!--/ Paper video. -->
        </div>
      </section>

    <section class="section">
        <div class="container is-max-desktop">
            <div class="container is-max-desktop">
                <div class="hero-body">
                    <h2 class="title is-4">Method Overview</h2>
                    <img src="./static/images/pipeline.png" height="150%" />
                      <p>
                        Our framework consists of three modules: The video encoder is used to extract visual representations of the input video. 
                        The motion VQ-VAE learns a mapping between the raw motion and discrete code sequences. The reaction generation module extracts 
                        interaction intention from visual representations and uses it to guide the generation of code indices. During training, the video 
                        and GT reactive motion are input into HERO. As for inference, only the video is provided. Note that we omit the residual motion 
                        refinement from the figure for clarity.
                      </p>
                </div>
            </div>

            <div class="container is-max-desktop">
                <div class="hero-body">
                    <h2 class="title is-4">ViMo Dataset</h2>
                    <img src="./static/images/dataset.png" height="150%" />
                      <p>
                        <b>ViMo dataset</b> contains 32 subcategorized interactions, each belonging to one of three broad categories: 
                          <span style="color: rgb(0, 0, 255);">human-human interactions</span>, 
                          <span style="color: rgb(0, 160, 0);">animal-human interactions</span>, and 
                          <span style="color: rgb(255, 0, 0);">scene-human interactions</span>. Among them, human-human interactions cover 
                          daily socializing, sports, physical confrontations, and others.
                      </p>
                </div>
            </div>
            
            <div class="container is-max-desktop">
                <div class="hero-body">
                    <h2 class="title is-4">Experiment Results</h2>
                    <img src="./static/images/visual_comparisons.png" height="150%" />
                      <p>
                        <b>Visual comparisons</b> between the different methods given three distinct videos from ViMo test set.
                      </p>
                    <img src="./static/images/unseen.png" height="150%" />
                      <p>
                        <b>Visualized cases of generating on the Unseen set.</b> Note that the data of the subcategories to which each video in the figure 
                        belongs are not utilized when training HERO on the <b>Seen</b> set.
                      </p>
                </div>
            </div>

            <!--
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Method Overview</h2>
                </div>
            </div>
            <section class="hero teaser">
                <div class="container is-max-desktop">
                    <div class="hero-body">
                        <img src="./static/teaser/overview.jpg"/>
                    </div>
                </div>
            </section>
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <div class="content has-text-justified">
                        <p>Surface features from an input 3D mesh are encoded through a face convolution-based encoder and decoded through a StyleGAN2-inspired decoder to generate textures directly on the surface of the mesh.</p>
                        <p>To ensure that generated textures are realistic, the textured mesh is differentiably rendered from different view points and is critiqued by two discriminators.</p>
                        <p>An image discriminator D<sub>I</sub> operates on full image views from the real or rendered views, while a patch-consistency discriminator D<sub>P</sub> encourages consistency between views by operating on patches coming from a single real view or patches from different views of rendered images.</p>
                    </div>
                </div>
            </div>
            -->
    </section>

    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
          <h2 class="title">BibTeX</h2>
          <pre><code>
            @inproceedings{yu2025hero,
              title={HERO: Human Reaction Generation from Videos},
              author={Yu, Chengjun and Zhai, Wei and Yang, Yuhang and Cao, Yang and Zha, Zheng-Jun},
              journal={arXiv preprint arXiv:2503.08270},
              year={2025}
            }
          </code></pre>
        </div>
    </section>

    <footer class="footer">
        <div class="container">
          <div class="content has-text-centered">
            <a class="icon-link"
               href="https://arxiv.org/pdf/2503.08270">
              <i class="fas fa-file-pdf"></i>
            </a>
            <a class="icon-link" href="" class="external-link" disabled>
              <i class="fab fa-github"></i>
            </a>
          </div>
          <div class="columns is-centered">
            <div class="column is-8">
              <div class="content">
                <p>
                  This website is licensed under a <a rel="license"
                                                      href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                  Commons Attribution-ShareAlike 4.0 International License</a>.
                </p>
                <p>
                  Source code mainly borrowed from <a href="https://keunhong.com/">Keunhong Park</a>'s <a
                                      href="https://nerfies.github.io/">Nerfies website</a>.
                </p>
              </div>
            </div>
          </div>
        </div>
      </footer>

    <!-- Import maps polyfill -->
    <!-- Remove this when import maps will be widely supported -->
    <script
    async
    src="skin/custom/unpkg.com_es-module-shims@1.3.6_dist_es-module-shims.js"
    ></script>
    
    <script type="importmap">
    {
      "imports": {
        "three": "./js/three.module.js"
      }
    }
    </script>
    
    <script type="module">
    import * as THREE from "three";
    
    import { PLYLoader } from "./js/PLYLoader.js";
    import { OrbitControls } from "./js/OrbitControls.js";
    let div_to_scene = {
      hot1: {
        color: null,
      },
      hot2: {
        color: null,
      },
      hot3: {
        color: null,
      },
      hot4: {
        color: null,
      },
    
      nat1: {
        color: null,
      },
      nat2: {
        color: null,
      },
      nat3: {
        color: null,
      },
      nat4: {
        color: null,
      },
    
      damon1: {
        color: null,
      },
      damon1_support: {
        color: null,
      },
      damon2: {
        color: null,
      },
      damon2_support: {
        color: null,
      },
      damon3: {
        color: null,
      },
      damon3_support: {
        color: null,
      },
      damon4: {
        color: null,
      },
      damon4_support: {
        color: null,
      }
    };
    let mouse_button_down = false;
    let list_of_orbit_controls = [];
    
    function setup_camera(div_name) {
      let container = document.getElementById(div_name);
      let width = container.parentElement.clientWidth;
      let height = container.parentElement.clientHeight;
      console.log(width, height);
      let camera = new THREE.PerspectiveCamera(35, width / height, 0.1, 50);
      let camera_init_position = new THREE.Vector3(0, 0, 2.2);
      camera_init_position = camera_init_position.multiplyScalar(1.5);
      camera.position.set(
        camera_init_position.x,
        camera_init_position.y,
        camera_init_position.z
      );
      return camera;
    }
    
    function setup_render_divs(div_name, mesh_path) {
      let camera = setup_camera(div_name);
      let orbit_control = create_render_div(camera, div_name, mesh_path);
      list_of_orbit_controls.push(orbit_control);
    }
    
    function create_render_div(camera, div_id, mesh_path) {
      let container;
      let renderer, controls;
    
      init();
      animate();
    
      function init() {
        container = document.getElementById(div_id);
        let width = container.parentElement.clientWidth;
        let height = container.parentElement.clientHeight;
    
        div_to_scene[div_id]["color"] = new THREE.Scene();
        div_to_scene[div_id]["color"].background = new THREE.Color( 0xffffff );
    
        // PLY file
    
        const loader = new PLYLoader();
        loader.load(mesh_path, function (geometry) {
            geometry.computeVertexNormals();
            let material_color = new THREE.MeshPhongMaterial( { 
              color: 0xcce6ff, 
              vertexColors: THREE.VertexColors,
              specular: 0x222222,
              shininess: 10,
            });
    
            const mesh_color = new THREE.Mesh(geometry, material_color);
            div_to_scene[div_id]["color"].add(mesh_color);
          },
          (xhr) => {
            console.log((xhr.loaded / xhr.total) * 100 + "% loaded");
          },
          (error) => {
            console.log(error);
          }
        );
    
        // lights
    
        add_lights(div_to_scene[div_id]["color"]);
    
        // renderer
    
        renderer = new THREE.WebGLRenderer({ antialias: true });
        renderer.setPixelRatio(window.devicePixelRatio);
        renderer.setSize(width, height);
        renderer.outputEncoding = THREE.sRGBEncoding;
    
        container.appendChild(renderer.domElement);
    
        controls = new OrbitControls(camera, renderer.domElement);
        controls.enableDamping = false;
        controls.autoRotate = true;
    
        // resize
    
        window.addEventListener("resize", onWindowResize);
        controls.addEventListener("start", function () {
          controls.autoRotate = false;
        });
      }
      function onWindowResize() {
        let width = container.clientWidth;
        let height = container.clientHeight;
        camera.aspect = width / height;
        camera.updateProjectionMatrix();
        renderer.setSize(width, height);
      }
      function animate() {
        requestAnimationFrame(animate);
        controls.update();
        render();
      }
    
      function render() {
        renderer.render( div_to_scene[div_id]["color"], camera );
        controls.update();
      }
    
      return controls;
    }
    
    function add_lights(scene) {
      scene.add(new THREE.HemisphereLight(0x443333, 0x111122, 0.05));
      const spotLight = new THREE.SpotLight(0xffffff, 0.5);
      spotLight.position.set(0.0, 0.5, 1);
      const spotLight2 = new THREE.SpotLight(0xffffff, 0.25);
      spotLight2.position.set(-2, 0.3, -0.2);
      const spotLight3 = new THREE.SpotLight(0xffffff, 0.25);
      spotLight3.position.set(2, -0.3, 0.2);
      const spotLight4 = new THREE.SpotLight(0xffffff, 0.25);
      spotLight4.position.set(0.0, 1, -2);
      const spotLight5 = new THREE.SpotLight(0xffffff, 0.05);
      spotLight5.position.set(0, -2.5, -1);
      spotLight.position.multiplyScalar(10);
      scene.add(spotLight);
      scene.add(spotLight2);
      scene.add(spotLight3);
      scene.add(spotLight4);
      scene.add(spotLight5);
    }
    
    document.addEventListener("keydown", logKey);
    
    function logKey(evt) {
      if (evt.keyCode === 82 && !mouse_button_down) {
        reset_orbit_controls();
      }
    }
    
    function reset_orbit_controls() {
      list_of_orbit_controls.forEach((oc) => {
        oc.reset();
        oc.autoRotate = false;
      });
    }
    
    document.body.onmousedown = function (evt) {
      if (evt.button === 0) mouse_button_down = true;
    };
    document.body.onmouseup = function (evt) {
      if (evt.button === 0) mouse_button_down = false;
    };
    
    window.onload = function () {
      let slider = document.getElementsByClassName("slider")[0];
      slider.removeAttribute("tabIndex");
      setup_render_divs(
        "hot1",
        "./static/plys/Carry_Backpack_01.ply"
      );
      setup_render_divs(
        "hot2",
        "./static/plys/bag_aff.ply"
      );
      setup_render_divs(
        "hot3",
        "./models/hot/deco_vcoco_000000537864.ply"
      );
      setup_render_divs(
        "hot4",
        "./models/hot/deco_vcoco_000000576589.ply"
      );
    
      setup_render_divs(
        "nat1",
        "./models/internet_yoga/pexels-photo-207569.ply"
      );
      setup_render_divs(
        "nat2",
        "./models/internet_yoga/pexels-photo-3622517.ply"
      );
      setup_render_divs(
        "nat3",
        "./models/internet_yoga/pexels-photo-15732209.ply"
      );
      setup_render_divs(
        "nat4",
        "./models/internet_yoga/213.ply"
      );
    
      setup_render_divs(
        "damon1",
        "./models/damon/hake_train2015_HICO_train2015_00000082.ply"
      );
      setup_render_divs(
        "damon1_support",
        "./models/damon/hake_train2015_HICO_train2015_00000082_support.ply"
      );
      setup_render_divs(
        "damon2",
        "./models/damon/vcoco_000000350231.ply"
      );
      setup_render_divs(
        "damon2_support",
        "./models/damon/vcoco_000000350231_support.ply"
      );
      setup_render_divs(
        "damon3",
        "./models/damon/vcoco_000000420649.ply"
      );
      setup_render_divs(
        "damon3_support",
        "./models/damon/vcoco_000000420649_support.ply"
      );
      setup_render_divs(
        "damon4",
        "./models/damon/vcoco_000000577928.ply"
      );
      setup_render_divs(
        "damon4_support",
        "./models/damon/vcoco_000000577928_support.ply"
      );
    };
    </script>
</body>

</html>
